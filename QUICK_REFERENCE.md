# Agent Amigos 2025 - Quick Reference Card

## ğŸš€ Quick Start (5 Minutes)

### 1ï¸âƒ£ Install

```bash
cd backend
pip install -r requirements.txt
```

### 2ï¸âƒ£ Initialize

```bash
python setup_enhancement.py
```

### 3ï¸âƒ£ Set Up Models (Choose One)

```bash
# Option A: Ollama (Recommended)
ollama pull qwen:70b mistral
ollama serve

# Option B: Cloud APIs
export OPENAI_API_KEY="sk-..."
export GROQ_API_KEY="..."
```

### 4ï¸âƒ£ Start

```bash
# Terminal 1
python backend/agent_init.py

# Terminal 2
cd frontend && npm run dev
```

### 5ï¸âƒ£ Open

```
http://localhost:5173
```

---

## ğŸ“š File Structure

```
backend/core/
â”œâ”€â”€ model_manager.py          # 15+ models, routing, stats
â”œâ”€â”€ learning_engine.py        # Memory, skills, patterns
â”œâ”€â”€ adaptive_agent.py         # Multi-strategy reasoning
â””â”€â”€ api_endpoints.py          # 17 REST endpoints

frontend/src/components/
â”œâ”€â”€ ModelDashboard.jsx        # Model management UI
â”œâ”€â”€ ModelDashboard.css        # Model styling
â”œâ”€â”€ AgentCapabilities.jsx     # Agent capabilities UI
â””â”€â”€ AgentCapabilities.css     # Agent styling

docs/
â”œâ”€â”€ OPENSOURC_AI_ENHANCEMENT.md    # Latest models
â”œâ”€â”€ IMPLEMENTATION_GUIDE.md         # Setup guide
â”œâ”€â”€ ARCHITECTURE_2025.md            # System design
â”œâ”€â”€ ENHANCEMENT_COMPLETE.md         # Summary
â””â”€â”€ QUICK_REFERENCE.md             # This file
```

---

## ğŸ¯ Available Models (15+)

### Local (Ollama)

| Model             | Best For          | Speed     |
| ----------------- | ----------------- | --------- |
| **Qwen 2.5 70B**  | Reasoning, Code   | Medium    |
| **Llama 3.3 70B** | General, Balanced | Medium    |
| **Mistral Large** | Fast, Coding      | Fast      |
| **Phi 3.5**       | Lightweight, Edge | Very Fast |

### Cloud APIs

| Provider       | Model       | Best For    |
| -------------- | ----------- | ----------- |
| **OpenAI**     | GPT-4o      | Multimodal  |
| **Groq**       | Llama 3.3   | Ultra-fast  |
| **DeepSeek**   | DeepSeek-V3 | Reasoning   |
| **OpenRouter** | Multiple    | Flexibility |

---

## ğŸ’» API Quick Commands

### Models

```bash
# List all models
curl http://localhost:8000/agent/models/available

# Get best model for task
curl "http://localhost:8000/agent/models/best-for-task?task_type=code"

# Get model stats
curl http://localhost:8000/agent/models/stats
```

### Agents

```bash
# List all agents
curl http://localhost:8000/agent/capabilities

# Get agent details
curl http://localhost:8000/agent/capabilities/CodeAgent

# Execute task
curl -X POST http://localhost:8000/agent/agent/CodeAgent/execute \
  -H "Content-Type: application/json" \
  -d '{"task":"explain recursion"}'
```

### Learning

```bash
# Get learning stats
curl http://localhost:8000/agent/learning/stats

# Submit feedback
curl -X POST http://localhost:8000/agent/learning/feedback \
  -H "Content-Type: application/json" \
  -d '{"interaction_id":"123","feedback":"Great!","rating":5}'
```

### Health

```bash
curl http://localhost:8000/agent/models/health
curl http://localhost:8000/agent/agents/health
```

---

## ğŸ”‘ Environment Variables

```bash
# OpenAI
export OPENAI_API_KEY="sk-..."
export OPENAI_MODEL="gpt-4o"

# Groq
export GROQ_API_KEY="..."
export GROQ_MODEL="llama-3.3-70b-versatile"

# Grok (X.AI)
export GROK_API_KEY="..."
export XAI_API_KEY="..."

# DeepSeek
export DEEPSEEK_API_KEY="..."

# OpenRouter
export OPENROUTER_API_KEY="..."

# Local Ollama
export OLLAMA_BASE_URL="http://localhost:11434"
```

---

## ğŸ§ª Test Features

### Test Model Selection

```python
from backend.core.model_manager import get_model_manager

manager = get_model_manager()
model = manager.get_best_model_for_task("code_generation")
print(f"Selected: {model.name}")
```

### Test Learning Engine

```python
from backend.core.learning_engine import get_learning_engine

engine = get_learning_engine()
engine.store_interaction(
    agent_name="TestAgent",
    task="test task",
    input_text="input",
    output_text="output",
    success=True,
    model_used="qwen:70b",
    duration_ms=1000,
    tools_used=["test"]
)
```

### Test Agent Execution

```python
from backend.core.adaptive_agent import get_or_create_agent

agent = get_or_create_agent("TestAgent")
status = agent.get_agent_status()
print(f"Agent stats: {status}")
```

---

## ğŸ“Š Key Metrics to Track

### Per Model

- âœ… Success rate (%)
- âœ… Avg response time (ms)
- âœ… Total interactions
- âœ… Cost (per 1K tokens)

### Per Agent

- âœ… Total interactions
- âœ… Success rate (%)
- âœ… Skills (proficiency %)
- âœ… Most used tools

### Global

- âœ… Best models by task
- âœ… Model rankings
- âœ… Learning efficiency

---

## ğŸ® UI Features

### Model Dashboard

- [ ] Sort by success rate
- [ ] Filter by provider
- [ ] View performance metrics
- [ ] See cost analysis
- [ ] Select preferred model

### Agent Capabilities

- [ ] View all agents
- [ ] Check skill levels
- [ ] See success patterns
- [ ] Monitor performance
- [ ] Track learning progress

---

## ğŸ”’ Security Checklist

- âœ… Use environment variables for keys
- âœ… Run models locally with Ollama
- âœ… Enable audit logging
- âœ… Limit agent scopes
- âœ… Rate limit API calls
- âœ… Validate all inputs
- âœ… Use HTTPS in production

---

## ğŸ› Troubleshooting

### Issue: Models Not Loading

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama
ollama serve

# Or check API keys
echo $OPENAI_API_KEY
```

### Issue: Memory Issues

```bash
# Use lighter model
# Phi 3.5 (3.8B) instead of Llama (70B)
# or use 8-bit quantization
```

### Issue: ChromaDB Error

```python
# Learning engine auto-falls back to in-memory
# No action needed
```

### Issue: API Rate Limit

```python
# Built-in exponential backoff handles this
# Retries up to 3 times automatically
```

---

## ğŸ“– Documentation Map

| Document                         | Purpose                | Length    |
| -------------------------------- | ---------------------- | --------- |
| **OPENSOURCE_AI_ENHANCEMENT.md** | Latest models research | 200 lines |
| **IMPLEMENTATION_GUIDE.md**      | Setup and deployment   | 400 lines |
| **ARCHITECTURE_2025.md**         | System design          | 300 lines |
| **ENHANCEMENT_COMPLETE.md**      | Project summary        | 500 lines |
| **QUICK_REFERENCE.md**           | This cheat sheet       | 300 lines |

---

## ğŸ¯ Learning System

### How It Works

1. Task executed
2. Result stored in memory
3. Patterns extracted
4. Skills updated
5. Next task uses learned patterns

### User Feedback Loop

```
Task â†’ Execute â†’ User Rates â†’ Learn â†’ Next Task Better
```

---

## ğŸš€ Next Steps

1. âœ… Install dependencies
2. âœ… Initialize systems
3. âœ… Set up models
4. âœ… Start backend/frontend
5. âœ… Open browser
6. âœ… Select preferred model
7. âœ… Execute tasks
8. âœ… Give feedback
9. âœ… Watch agent improve

---

## ğŸ’¡ Pro Tips

1. **Start with Qwen 2.5** - Best all-around performance
2. **Use Groq for speed** - Ultra-fast local inference
3. **Enable learning** - Agents improve over time
4. **Monitor dashboard** - Real-time metrics
5. **Try feedback** - Helps agents learn faster
6. **Check patterns** - See what's working
7. **Profile models** - Find best for your tasks

---

## ğŸ“ Key Classes

```python
# Model Management
from backend.core.model_manager import get_model_manager
manager = get_model_manager()

# Learning System
from backend.core.learning_engine import get_learning_engine
engine = get_learning_engine()

# Agent Execution
from backend.core.adaptive_agent import get_or_create_agent
agent = get_or_create_agent("MyAgent")

# API Routes
from backend.core.api_endpoints import router
app.include_router(router)
```

---

## âœ¨ Feature Highlights

âœ… **15+ Models** - Local and cloud  
âœ… **Self-Learning** - Improves over time  
âœ… **Multi-Strategy** - Different reasoning approaches  
âœ… **Real-Time Monitoring** - Live dashboards  
âœ… **User Preferences** - Learns what you like  
âœ… **Skill Tracking** - See agent development  
âœ… **Pattern Learning** - Extract best practices  
âœ… **Auto-Selection** - Best model for task

---

## ğŸ“ Learning Levels

| Level      | Range  | Status      |
| ---------- | ------ | ----------- |
| Expert     | 90%+   | ğŸŸ¢ Ready    |
| Proficient | 70-89% | ğŸŸ¡ Good     |
| Learning   | 50-69% | ğŸŸ  Training |
| Developing | <50%   | ğŸ”´ New      |

---

## ğŸ“± Responsive Design

- âœ… Desktop (1920px+)
- âœ… Tablet (768px-1024px)
- âœ… Mobile (320px-767px)
- âœ… Dark theme
- âœ… Touch-friendly

---

## ğŸ”„ Update Frequency

| Component          | Refresh Rate |
| ------------------ | ------------ |
| Model Dashboard    | 5 seconds    |
| Agent Capabilities | 10 seconds   |
| Statistics         | 30 seconds   |
| Learning Stats     | On demand    |

---

## ğŸ“¦ Dependencies

### Backend (25 packages)

- fastapi, uvicorn, pydantic
- ollama, chromadb, llama-index
- instructor, autogen, crewai
- requests, aiohttp, playwright

### Frontend (1 tool)

- React 18, Axios, CSS3

---

**Version**: 2.0 (2025)  
**Status**: âœ… Production Ready  
**Updated**: December 26, 2025

---

**Need help?** Check the documentation folder or run `python setup_enhancement.py --help`
